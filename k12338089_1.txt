The lecture, which was lead by Oliver Bimber, focused on the research that he is undertaking in developing technology that allows drones to see through obstructions (or "occlusions''), for example tree canopies, in order to spot early signs of a wildfire, or to find a missing hiker. Oliver went in-depth when talking about the technology itself, and the various principles under which it functions. He brought up examples of how the technology would work and the many issues that it has to overcome. Seeing as how I had little knowledge on the matter, I was glad that Mr. Bimber explained it in great detail, breaking things down into easy-to-understand chunks, and providing visual examples. At first, I expected for the drones to interpret movement beneath canopies, much like a human would, but after hearing that it mostly functions on the InfraRed scale, it made so much more sense, as living organisms produce heat signatures that make them stand out in the environment. The main principle behind this, is known as 'Synthetic Aperture Sensing', where the drone takes multiple, small images and combines them to create a larger image, with many layers to it (like an onion) that the drone can then sift through to find its looking for.
I believe that the talk fit its audience well, as anyone, with any level of experience could listen to it and understand the bulk of what was being said, as Oliver defined many abbreviations and used simple phrases to get his message across. This helped make the topic more understandable to his audience, which might not have been interested in drone technology before. I personally found it very interesting and I realized that drones have much more potential than I had initially thought. They are able to be used for more than just photography and entertainment, which made a lot of sense, considering their small frame and ease of handling. While the topic was quite in-depth about an unfamiliar field of study, there wasn't anything that didn't make sense to me, as it was quite logical in the solutions to the many problems that the project faced, for example if a drone was to scan for people in a forest first, and then remove the 'occlusion', the accuracy of the results would be low. Whereas if it removes occlusion first, and then looks for people, then the accuracy skyrockets.
