The lecture was held by Professor Markus Sheld, who talked about how Music Recommender Systems worked, and the problems that they work to solve. The lecture went in-depth about how systems behind popular services like Spotify, Deezer and Youtube Music worked, down to the different types of decision making that these systems might do, like; Collaborative and Context-based Filtering, or Context-Aware Recommendation. The lecture then explored the various issues that these systems face when trying to recommend new music to a user. Problems like Cold-start, Over-personalization and bias can have an effect on the user's experience when using services like Spotify. Fairness and Discrimination towards certain types of music artists also fell into the broad sphere of Bias, that the system tries to deal with; a male artist is statistically recommended more often to more people, than their female counterpart. This form of discrimination is also based on the artist's race.
One of the many solutions to these problems, was the act of De-biasing the system, i.e. down-ranking more popular and often-recommended artists, in order to level the playing field for musicians, as well as broaden the recommendations given by the system. I personally think this a good solution to the main problem of "filter-bubble"-ing, as I've noticed that I often get recommended songs from the same few artists that I listen to. While I enjoy their music, it can get a bit repetitive, to the point where I go out of my way to look for new music
I believe that this talk was well suited for its target audience, as 1st Year Bachelor students are mostly young and listen to music often in their day-to-day lives. This lecture brought to light the inner-workings of their favorite music providers, and shed light on the problems that these students might have noticed, but never considered. I personally found it very interesting how these recommender systems worked behind the scenes, and it made me think of what my ideal approach to recommending music (or any type of product for that matter) would be. The more I learned, the more complex the situation became, as bias and discrimination would be problems that I would also need to face, when making a recommender system, as there is no one-size-fits-all solution, only band-aids that cover up the problem. Like how would you deal with a "Cold-Start" while avoiding filter-bubbles and biases?
